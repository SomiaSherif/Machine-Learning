#!/usr/bin/env python
# coding: utf-8

# In[130]:


import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

from tensorflow import keras
from keras.preprocessing.image import ImageDataGenerator as imgen
from keras.models import Model
from keras.layers import GlobalAveragePooling2D,Dense,Dropout,Input
from keras.applications.xception import Xception
from keras.applications.xception import preprocess_input
from keras.callbacks import ModelCheckpoint,EarlyStopping

from sklearn.metrics import classification_report,confusion_matrix
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import roc_auc_score
import tensorflow as tf


# In[131]:


traingen = imgen(preprocessing_function=preprocess_input,
                zoom_range=0.2,
                 shear_range=0.2,
                 horizontal_flip=True,
                 validation_split=0.12
                )
testgen = imgen(preprocessing_function=preprocess_input)


# In[132]:


path="C:/Users/ranya\Downloads/archive (1)/afhq"


# In[133]:


tf.keras.preprocessing.image.load_img('C:/Users/ranya\Downloads/archive (1)/afhq/train/cat/flickr_cat_000018.jpg')


# In[134]:


trainds = traingen.flow_from_directory("C:/Users/ranya/Downloads/archive (1)/afhq/train",
                                      target_size=(128,128),
                                       seed = 123,
                                       batch_size=128,
                                       class_mode="categorical",
                                       subset="training"
                                      )
valds = traingen.flow_from_directory("C:/Users/ranya/Downloads/archive (1)/afhq/train",
                                     target_size=(128,128),
                                      seed =123,
                                      batch_size = 128,
                                      class_mode="categorical",
                                      subset="validation"
                                     )
testds = testgen.flow_from_directory("C:/Users/ranya/Downloads/archive (1)/afhq/val",
                                    target_size=(128,128),
                                      seed =123,
                                      batch_size = 128,
                                      class_mode="categorical",
                                     shuffle=False
                                    )


# In[135]:


from skimage import io
image = io.imread('C:/Users/ranya\Downloads/archive (1)/afhq/train/cat/flickr_cat_000018.jpg')  

# plotting the original image
i, (im1) = plt.subplots(1)
i.set_figwidth(15)
im1.imshow(image)


# In[136]:


i, (im1, im2, im3, im4) = plt.subplots(1, 4, sharey=True)
i.set_figwidth(20) 

im1.imshow(image)  #Original image
im2.imshow(image[:, : , 0]) #Red
im3.imshow(image[:, : , 1]) #Green
im4.imshow(image[:, : , 2]) #Blue
i.suptitle('Original & RGB image channels')


# In[137]:


import skimage
gray_image = skimage.color.rgb2gray(image)
plt.imshow(gray_image, cmap = 'gray')


# In[138]:


norm_image = (gray_image - np.min(gray_image)) / (np.max(gray_image) - np.min(gray_image))
plt.imshow(norm_image)


# In[139]:


from numpy import expand_dims
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.preprocessing.image import ImageDataGenerator

# convert to numpy array
data = img_to_array(image)

# expand dimension to one sample
samples = expand_dims(image, 0)

# create image data augmentation generator
datagen = ImageDataGenerator(width_shift_range=[-200,200])

# create an iterator
it = datagen.flow(samples, batch_size=1)
fig, im = plt.subplots(nrows=1, ncols=3, figsize=(15,15))

# generate batch of images
for i in range(3):
     image = next(it)[0].astype('uint8')
 
    # plot image
     im[i].imshow(image) 
        


# In[140]:


import cv2
image=cv2.imread("C:/Users/ranya\Downloads/archive (1)/afhq/train/cat/flickr_cat_000018.jpg")
image = image / 255
image


# In[141]:


classes = trainds.class_indices
classes = list(classes.keys())
classes


# In[142]:


dist = trainds.classes
sns.countplot(x=dist);


# In[143]:


def showImages(x,y):
    plt.figure(figsize=[15,11])
    for i in range(16):
        plt.subplot(4,4,i+1)
        plt.imshow(x[i])
        plt.title(classes[np.argmax(y[i])])
        plt.axis("off")
    plt.show()
    
x,y = next(trainds)
showImages(x,y)


# In[144]:


base_model = Xception(include_top = False,weights="imagenet",pooling="avg",input_shape=(128,128,3))

base_model.trainable = False


# In[145]:


image_input = Input(shape=(128,128,3))
x = base_model(image_input,training = False)
x = Dense(128,activation = "relu")(x)
image_output = Dense(3,activation="softmax")(x)
model = Model(image_input,image_output)


# In[146]:


model.compile(optimizer="adam",loss="categorical_crossentropy",metrics=["accuracy"])

# callbacks
my_calls = [EarlyStopping(monitor="val_accuracy",patience=3),
            ModelCheckpoint("xception_weights_tf_dim_ordering_tf_kernels_notop.h5",verbose= 1 ,save_best_only=True)]


# In[147]:


model.summary()


# In[148]:


hist = model.fit(trainds, epochs=15, validation_data=valds, callbacks=my_calls)


# In[149]:


model.evaluate(testds)


# In[150]:


plt.figure(figsize=(15,6))

plt.subplot(1,2,1)
plt.plot(hist.epoch,hist.history['accuracy'],label = 'Training')
plt.plot(hist.epoch,hist.history['val_accuracy'],label = 'validation')

plt.title("Accuracy")
plt.legend()

plt.subplot(1,2,2)
plt.plot(hist.epoch,hist.history['loss'],label = 'Training')
plt.plot(hist.epoch,hist.history['val_loss'],label = 'validation')

plt.title("Loss")
plt.legend()
plt.show()


# In[151]:


pred = model.predict(testds,verbose=1)


# In[152]:


pred = [np.argmax(i) for i in pred]


# In[153]:


y_test = testds.classes


# In[154]:


print(classification_report(pred,y_test))


# In[155]:


from sklearn.metrics import confusion_matrix, accuracy_score
cm = confusion_matrix(y_test, pred)
print(cm)
accuracy_score(y_test, pred)


# In[156]:


sns.heatmap(confusion_matrix(pred,y_test),annot = True, fmt = "d", cmap = "BuPu");


# In[157]:


# multi-class classification
from sklearn.datasets import make_classification
from sklearn.multiclass import OneVsRestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score

# generate 2 class dataset
X, y = make_classification(n_samples=1000, n_classes=3, n_features=20, n_informative=3, random_state=42)

# split into train/test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)

# fit model
clf = OneVsRestClassifier(LogisticRegression())
clf.fit(X_train, y_train)
pred = clf.predict(X_test)
pred_prob = clf.predict_proba(X_test)

# roc curve for classes
fpr = {}
tpr = {}
thresh ={}
n_class = 3

for i in range(n_class):    
    fpr[i], tpr[i], thresh[i] = roc_curve(y_test, pred_prob[:,i], pos_label=i)
    
# plotting    
plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Class 0 vs Rest')
plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Rest')
plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Class 2 vs Rest')
plt.title('Multiclass ROC curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive rate')
plt.legend(loc='best')
plt.savefig('Multiclass ROC',dpi=300);  


# In[ ]:




